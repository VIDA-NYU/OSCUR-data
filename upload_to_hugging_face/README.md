# Uploading Datasets to Hugging Face ðŸ¤—

This folder contains scripts and documentation for uploading datasets from this repository to the [Hugging Face Hub](https://huggingface.co/datasets). It supports multiple datasets generated by the project and outlines a reproducible workflow.


## Steps to Upload a Dataset

Follow these steps to upload any of the generated datasets to Hugging Face:

### 1. Prepare Your Dataset

Ensure your dataset is in one of the following formats:
- CSV, TSV, JSON
- Text files or image folders
- Parquet

Organize the data files clearly (e.g., under `data/`), ideally with train/test/dev splits if applicable.


### 2. Install Required Tools

Make sure you have the Hugging Face tools installed:

```bash
pip install huggingface_hub datasets
```

Login to your Hugging Face account:

```
huggingface-cli login
```

### 3. Create a Dataset Repository on Hugging Face

Go to https://huggingface.co/new and create a new repository:
- Repository type: Dataset
- Name: your-dataset-name
- Visibility: Public or private

### 4. Clone the Dataset Repository Locally

```
git lfs install
git clone https://huggingface.co/datasets/<your-username>/<your-dataset-name>
cd <your-dataset-name>
```
### 5. Add Your Dataset Files
Copy the dataset files into the cloned repository. A suggested structure:

```
your-dataset-name/
â”œâ”€â”€ README.md           # Dataset description
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ dataset_infos.json  # (Optional) Metadata
â”œâ”€â”€ dataset_script.py   # (Optional) HF loading script
```

Update README.md with details such as:
- Dataset description
- Source
- Tasks
- How to use it

### 6. Track and Push Large Files with Git LFS
If you're including large files (e.g., CSVs):

```
git lfs track "*.csv"
git add .gitattributes
```
Then commit and push:

```
git add .
git commit -m "Add dataset files"
git push
```

### 7. (Optional) Create a Loading Script
If you want your dataset to be directly loadable via:

```
from datasets import load_dataset
load_dataset("your-username/your-dataset-name")
```

Include a ``dataset_script.py`` following Hugging Face's custom loader format. This script uses the ``datasets`` loading API to define ``DatasetBuilder``.
<details>
<summary>
   How to Use <code>dataset_script.py</code>
</summary>

>
> - Place this script alongside your data/train.csv, data/test.csv, etc.
> - Push it to your Hugging Face dataset repo.
> - Then test it:
>    ```bash
>     from datasets import load_dataset
>     dataset = load_dataset("your-username/your-dataset-name")
>    ```
</details>


## ðŸ“Œ Notes
- Git LFS is required for large files.
- You can update datasets later by re-pushing to the repo.
- Use meaningful and clean structure for discoverability.

Happy uploading! ðŸš€
